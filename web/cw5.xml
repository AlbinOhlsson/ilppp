<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC
        "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
    <head>
        <title>Assignment #5: Dependency parsing</title>
    </head>
    <body>
        <!--<h1>Assignment #5: Dependency parsing</h1>-->
        <h2>Objectives</h2>
        <p>The objectives of this assignment are to:</p>
        <ul>
            <li>Know what a dependency graph is</li>
            <li>Understand the principles of Nivre's parsing mechanisms</li>
            <li>Extend Nivre's parser with a guiding predicate that parses an annotated dependency graph</li>
            <li>Extract features to learn parsing actions from an annotated corpus</li>
            <li>In this assignment, you will only generate the Weka models from the extracted features. You will
                complete the parser and apply it in the next assignment.
            </li>
        </ul>
        <h2>Organization and location</h2>
        <p>The fifth lab session will take place on</p>
        <ul>
            <li>Group 1: Wednesday, October 7 from 10:15 to 12:00 in the Alpha room</li>
            <li>Group 2: Wednesday, October 7 from 10:15 to 12:00 in the Beta room</li>
            <li>Group 3: Wednesday, October 7 from 13:15 to 15:00 in the Beta room</li>
        </ul>
        <p>You can work alone or collaborate with another student.</p>
        <p>Each group will have to:</p>
        <ul>
            <li>Write a program that parses a sentence when the dependency graph is known</li>
            <li>Extract features from the parsing actions.</li>
        </ul>
        <h2>Programming</h2>
        <p>This assignment is inspired by the shared task of the Tenth conference on computational natural language
            learning,<a href="http://ilk.uvt.nl/conll/">CONLL-X</a>, and uses a subset of their data. The conference
            site contains a description of multilingual dependency parsing, reference papers, training and test sets for
            a variety of languages, as well as evaluation programs. See also <a
                    href="http://depparse.uvt.nl/SharedTaskWebsite.html">CONLL 2007</a>, on the same topic.
        </p>
        <p>In this session, you will implement a dependency parser for Swedish. Should you want to use another corpus,
            please tell me in advance.
        </p>
        <h3>Choosing a training and a test sets</h3>
        <p>The CONLL-X annotated corpora and annotation scheme are available <a
                href="http://ilk.uvt.nl/conll/post_task_data.html">here</a>. The Swedish corpus called
            <i>Talbanken</i>
            was originally collected and annotated in Lund and modified by Joakim Nivre. You can read details on the
            corpus and references <a href="http://stp.ling.uu.se/~nivre/swedish_treebank/">here</a>.
        </p>
        <ol>
            <li>In this assignment, you will use the CONLL-X Swedish corpus. Download the tar archives containing the
                training and test sets for Swedish and uncompress them: [<a
                        href="http://ilk.uvt.nl/conll/free_data.html">data sets</a>]. Local copies: [<a
                        href="http://fileadmin.cs.lth.se/cs/Education/EDAN20/corpus/conllx/sv/swedish_talbanken05_train.conll">
                    training set</a>] [<a
                        href="http://fileadmin.cs.lth.se/cs/Education/EDAN20/corpus/conllx/sv/swedish_talbanken05_test_blind.conll">
                    test set</a>] [<a
                        href="http://fileadmin.cs.lth.se/cs/Education/EDAN20/corpus/conllx/sv/swedish_talbanken05_test.conll">
                    test set with answers</a>].
            </li>
        </ol>
        <h3>Nivre's parser</h3>
        <p>For each sentence with a projective dependency graph, there is an action sequence that enables Nivre's parser
            to generate this graph. Gold standard parsing corresponds to the sequence of parsing actions, left-arc (<tt>
                la</tt>), right-arc (<tt>ra</tt>), shift (<tt>sh</tt>), and reduce (<tt>re</tt>) that produces the
            manually-obtained, gold standard, graph.
        </p>
        <p>Action sequences can be trained from an annotated corpus, or more precisely the next action can be trained
            from the current parsing context. To be able to predict the next action, gold standard parsing must also
            extract feature vectors at each step of the parsing procedure. The simplest parsing context corresponds to
            words' part of speech on the top of the stack and head of the input list (the queue).
        </p>
        <p>Once the data collected, the training procedure will produce a 4-class classifier that you will embed in
            Nivre's parser to choose the next action. During parsing, Nivre's parser will call the classifier to choose
            the next action in the set {<tt>la</tt>,<tt>ra</tt>,<tt>sh</tt>,<tt>re</tt>} using the current context.
        </p>
        <ol>
            <li>Discuss how to extend Nivre's parser to carry out a gold standard parsing. Given a manually-annotated
                dependency graph, what are the conditions on the stack and the current input list -- the queue -- to
                execute left-arc, right-arc, shift, or reduce? Start with left-arc and right-arc, which are the simplest
                ones.
            </li>
            <li>As main features, you will use three models:
                <ul>
                    <li>The top of the stack and the first word of the input list</li>
                    <li>The two first words on the top of the stack and the two first words of the input list</li>
                    <li>A feature vector that you will design that will extend the previous one with at least one
                        feature. You can read
                        <a href="http://www.aclweb.org/anthology/C/C10/C10-1093.pdf">this paper</a>
                        (Table 6) to build your vector. Use only POS-based features as your machine--learning algorithm
                        would not scale well with features with many values such as lexical (word) features.
                    </li>
                </ul>
            </li>
            <li>Nivre's parser sets constraints to actions. Name a way to encode these constraints as features. Think of
                Boolean features.
            </li>
            <li>Read this program [<a href="http://fileadmin.cs.lth.se/cs/Education/EDAN20/programs/parser/src.zip">
                1</a>], notably <tt>ReferenceParser.java</tt>. Edit the data paths in
                <tt>Constants.java</tt>
                so that they fit your configurations. You will run the
                <tt>ReferenceParser</tt>
                program. <!--You can use the command: <tt>java -Xmx500m -cp dist/nivre.jar parser.ReferenceParser</tt>.-->
                For now, it never terminates.
            </li>
        </ol>
        <h3>Parsing functions</h3>
        <p>
            Using the actions in the set {<tt>la</tt>,<tt>ra</tt>,<tt>sh</tt>,<tt>re</tt>} will produce an unlabelled
            graph. It is easy to extend the parser so that it can label the graph with grammatical functions. In this
            case, we must complement the actions
            <tt>la</tt>
            and
            <tt>ra</tt>
            with their function using this notation for example:<tt>la.++</tt>,<tt>la.+A</tt>,<tt>la.+F</tt>,<tt>
            la.AA</tt>,<tt>la.AG</tt>, etc. where the prefix is the action and the suffix is the function.
        </p>
        <p>Read the complete list of actions extracted from the Swedish corpus in CoNLL-X <a
                href="http://fileadmin.cs.lth.se/cs/Education/EDAN20/corpus/conllx/sv/domain_functions.arff">here</a>.
        </p>
        <h3>Extracting features (I)</h3>
        <p>The final goal is to parse the Swedish corpus in CoNLL-X and produce a labelled and unlabelled dependency
            graph. You will show the parsing results at the end of the 5th assignment. In this assignment, you will only
            generate the Weka models.
        </p>
        <p>You will consider three feature sets and you will learn the corresponding decision tree classifiers using
            Weka:
        </p>
        <ol>
            <li>The first set will use two parameters extracted from the stack and the queue,</li>
            <li>the second one, four parameters.</li>
            <li>For the third model, you will extract at least two more features, one of them being the part of speech
                of the word following the top of the stack in the sentence order.
            </li>
        </ol>
        <p>These sets will include two additional Boolean parameters, "can do left arc" and "can do reduce", which will
            model constraints on the parser's actions. In total, the feature sets will then have four (respectively six
            and eight) parameters.
        </p>
        <p>This means that the purpose of this assignment is to generate six Weka models:</p>
        <ol>
            <li>Three models for the unlabelled graphs</li>
            <li>Three models for the labelled graphs</li>
        </ol>
        <p>To carry this out:</p>
        <ol>
            <li>Modify the Java program and build the data sets (six in total). You will have to complete:
                <ul>
                    <li>the
                        <tt>extractFeatures()</tt>
                        method in
                        <tt>ReferenceParser.java</tt>
                        so that you extract the features.
                    </li>
                    <li>the
                        <tt>parse()</tt>
                        method in
                        <tt>ReferenceParser.java</tt>
                        so that you determine the action, for instance
                        <tt>la</tt>
                        or<tt>la.SS</tt>. You will write a conditional that calls the oracles and add the action to the
                        transition list using<tt>transitionList.add()</tt>. Don't forget to carry out the action in each
                        member of the conditional.
                    </li>
                </ul>
            </li>
            <li>Download
                <a href="http://fileadmin.cs.lth.se/cs/Education/EDAN20/corpus/conllx/sv/parsing_header4_java.arff">this
                    header
                </a>
                and create headers to fit the 2-parameter set, your parameter set, as well as the labelled graphs.
            </li>
            <li>Generate the six Weka models. (You must use Weka version 3.7.2 or higher.). You will evaluate the model
                accuracies (not the parsing accuracy) using the summary of the stratified cross-validation produced by
                Weka and the correctly classified instances
            </li>
        </ol>
        <p>The first lines of your ARFF file for the 4-parameter and labelled version should look like the except below:
        </p>
        <pre>
            nil nil ROOT NN false false sh
            ROOT nil NN ++ true false sh
            NN ROOT ++ NN true false sh
            ++ NN NN AV true false la.++
            NN ROOT NN AV true false ra.CC
            NN NN AV EN false true re
            NN ROOT AV EN true false la.SS
            ROOT nil AV EN true false ra.ROOT
            AV ROOT EN AJ false true sh
        </pre>
        <h2>Complement (Optional)</h2>
        <p>Read the text
            <i>An Efficient Algorithm for Projective Dependency Parsing</i>
            by Joakim Nivre (2003) [<a href="http://stp.lingfil.uu.se/~nivre/docs/iwpt03.pdf">pdf</a>]. You can find
            additional references <a href="http://stp.lingfil.uu.se/~nivre/docs/cv_eng.html">here</a>.
        </p>
    </body>
</html>
