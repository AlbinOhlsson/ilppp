{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Scikit learn with Quinlan's dataset\n",
    "Pierre Nugues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_file = 'weather-nominal.csv'\n",
    "column_names = ['outlook', 'temperature', 'humidity', 'windy', 'play']\n",
    "f = open(data_file).read()\n",
    "rows = f.strip().split('\\n')\n",
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the dataset in a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature matrix needs to be represented by a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_rows(rows, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    rows = [dict(zip(column_names, row.split(','))) for row in rows]\n",
    "    return rows\n",
    "data_set = split_rows(rows, column_names)\n",
    "data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the features and the classes and we store them in `X_dict` and `y_symbols`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_feats(data_set, class_name):\n",
    "    y_symbols = []\n",
    "    for obs in data_set:\n",
    "        y_symbols.append(obs.pop(class_name, None))\n",
    "    X_dict = data_set\n",
    "    return X_dict, y_symbols\n",
    "\n",
    "\n",
    "X_dict, y_symbols = extract_feats(data_set, 'play')\n",
    "print(X_dict)\n",
    "print(y_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize the feature matrix and carry out a one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec = DictVectorizer(sparse=False) # Should be true\n",
    "#vec = DictVectorizer(sparse=True) # Should be true\n",
    "X = vec.fit_transform(X_dict)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The class vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign *no* to 0 and *yes* to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = [0 if symb == 'no' else 1 for symb in y_symbols]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a numerical dataset, we can use a linear classifier and fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = linear_model.LogisticRegression()\n",
    "#classifier = svm.SVC()\n",
    "model = classifier.fit(X, y)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have trained a classifier and we predict the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hat = classifier.predict(X)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we use a test set (here the training set), we only need to use `transform` to vectorize the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_dict = X_dict\n",
    "X_test = vec.transform(X_test_dict)\n",
    "y_hat = classifier.predict(X_test)\n",
    "y_hat"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
